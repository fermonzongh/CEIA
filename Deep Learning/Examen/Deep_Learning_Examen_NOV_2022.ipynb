{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftXnmgdtOuZs"
   },
   "source": [
    "# Universidad de Buenos Aires\n",
    "# Deep Learning - Examen\n",
    "# Noviembre 2022\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEx1gM2sG4OP"
   },
   "source": [
    "El examen comienza al momento de recibir este correo y la ventana de entrega estará abierta hasta el domingo 18 de diciembre a las 20:00hs. Toda comunicación con otros alumnos respecto del examen y la resolución de los ejercicios, queda estrictamente prohibida. Los exámenes serán comparados desde el punto de vista de la redacción, de los resultados y del código para determinar que el trabajo fue 100% individual y único. El examen es a libro abierto, pudiendo utilizar los contenidos vistos en clase y otra bibliografía. Todas las soluciones deben ser originales y si se toman ideas de fuentes externas deben ser correctamente citas incluyendo el correspondiente link o página de libro.\n",
    "\n",
    "El formato de entrega debe ser un “link a un colab” (compartir a las siguientes direcciones: maxit1992@gmail.com y lelectronfou@gmail.com ) o un “link a un notebook en un github público” (tanto con los resultados, cómo el código y las explicaciones deben quedar guardados y visualizables en el correspondiente link).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlfSxrehmuYW"
   },
   "source": [
    "## Ejercicio 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FY2z-GSXoFvq"
   },
   "source": [
    "Se quiere encontrar el máximo de la siguiente función:\n",
    "\n",
    "$z = -(x - 2)^2 - (y - 3)^2 + 4$\n",
    "\n",
    "(a) Aplicar gradiente e igualar a zero para encontrar los valores de $x$ e $y$ donde $z$ tiene un máximo. Cuál es el valor del máximo?\n",
    "\n",
    "(b) Aplicar SGD para encontrar la ubicación del máximo de manera numérica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Gradiente de z = -2(x-2)i - 2(y-3)j .\n",
    "\n",
    "$$-2(x-2)=0$$\n",
    "\n",
    "$$x=2$$\n",
    "\n",
    "$$-2(y-3)=0$$\n",
    "\n",
    "$$y=3$$\n",
    "\n",
    "El punto donde z tiene un maximo es en el punto (2,3), con valor 4: \n",
    "$$-(2-2)^2 - (3-3)^2 + 4 = 4$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def gradient(var):\n",
    "    return np.array([-2*(var[0]-2),-2*(var[1]-3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El punto de maximo de z se encuentra en: [2. 3.]\n",
      "Con valor z = 4.0\n"
     ]
    }
   ],
   "source": [
    "delta = 10\n",
    "lr = 0.01\n",
    "start = np.random.rand(2)\n",
    "vector=start\n",
    "while delta >0.000001:\n",
    "    diff = lr*gradient(vector)\n",
    "    vector += diff\n",
    "    delta=np.sqrt(np.sum(np.square(diff)))\n",
    "print(\"El punto de maximo de z se encuentra en:\",np.round(vector))\n",
    "z=-(vector[0]-2)**2-(vector[1]-3)**2+4\n",
    "print(\"Con valor z =\",np.round(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CMta3Dj_Mjq"
   },
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_hXG5W6KMBx"
   },
   "source": [
    "\n",
    "\n",
    "En las siguientes imágenes, se presenta la traslación de un objeto en la capa de entrada de una CNN (el 2 de las imágenes inferiores) y las neuronas que se activan a la salida de dicha CNN para 2 tipos de propiedadedes de las CNN: *Invarianza al desplazamiento (translational invariance)* y *equivariancia al desplazamiento (translational equivariance)*.\n",
    "\n",
    "\n",
    "![a](https://drive.google.com/uc?export=view&id=1buWr91SCZcx4Zx55VLpAf1mCxqVgHgci)\n",
    "\n",
    "Imagen 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![b](https://drive.google.com/uc?export=view&id=1FqUKjutcRL-1Vay0HYY-1tXlISCZFH02)\n",
    "\n",
    "Imagen 2\n",
    "\n",
    "\n",
    "Preguntas:\n",
    "* a) ¿Qué imagen se corresponde con cuál propiedad? \n",
    "* b) ¿Cuál/cuáles de cada capa elemental de una CNN (convolución - activación - pooling) aporta cada propiedad?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Imagen 1: Invarianza translacional. Imagen 2: Equivarianza translacional\n",
    "\n",
    "b) La capa de convolucion aporta la equivarianza translacional y la capa de pooling aporta la invarianza translacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvsqmJwx_Rb8"
   },
   "source": [
    "## Ejercicio 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABeIRvAkKLy7"
   },
   "source": [
    "\n",
    "\n",
    "Para la siguiente red neuronal recurrente, se pide expresar las ecuaciones \"*unfolded*\" de la salida de la misma y de sus estados ocultos, si el vector de entrada son 3 muestras secuenciadas de la variable $x(t)$.\n",
    "\n",
    "![b](https://drive.google.com/uc?export=view&id=1Fz46GTK7Oy_w5OEgwLCLfHFMr7b6-AnL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ecuaciones de la RNN:\n",
    "\n",
    "$$ \\hat{y}(t) = w_{h1y} * h1(t) + w_{h2y} * h2(t) + by$$\n",
    "\n",
    "$$ h1(t) = w_{xh1} * x(t) + w_{h1h1} * h1(t-1) + w_{h2h1} * h2(t-1)+ bh1$$ \n",
    "$$ h2(t) = w_{xh2} * x(t) + w_{h2h2} * h2(t-1) + w_{h1h2} * h1(t-1)+ bh2 $$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden state inicializado en 0\n",
    "\n",
    "$$ h1(t=0) = w_{xh1} * x(t=0) + w_{h1h1} * h1(0) + w_{h2h1} * h2(0)+ bh1 = w_{xh1} * x(t=0) + bh1$$\n",
    "$$ h2(t=0) = w_{xh2} * x(t=0) + w_{h2h2} * h2(0) + w_{h1h2} * h1(0)+ bh2 = w_{xh2} * x(t=0) + bh2$$\n",
    "\n",
    "$$ \\hat{y}(t=0) = w_{h1y} * h1(t=0) + w_{h2y} * h2(t=0) + by$$\n",
    "\n",
    "$$ h1(t=1) = w_{xh1} * x(t=1) + w_{h1h1} * h1(t=0) + w_{h2h1} * h2(t=0)+ bh1$$ \n",
    "$$ h2(t=1) = w_{xh2} * x(t=1) + w_{h2h2} * h2(t=0) + w_{h1h2} * h1(t=0)+ bh2 $$ \n",
    "\n",
    "$$ \\hat{y}(t=1) = w_{h1y} * h1(t=1) + w_{h2y} * h2(t=1) + by$$\n",
    "\n",
    "$$ h1(t=2) = w_{xh1} * x(t=2) + w_{h1h1} * h1(t=1) + w_{h2h1} * h2(t=1)+ bh1$$ \n",
    "$$ h2(t=2) = w_{xh2} * x(t=2) + w_{h2h2} * h2(t=1) + w_{h1h2} * h1(t=1)+ bh2 $$ \n",
    "\n",
    "$$ \\hat{y}(t=2) = w_{h1y} * h1(t=2) + w_{h2y} * h2(t=2) + by$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WL2PjUnT_Uvk"
   },
   "source": [
    "## Ejercicio 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73yqE_Sslwif"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Descargar el dataset del siguiente link: https://drive.google.com/file/d/1X8_G5BpQMi-Nnbtms2RL8lcWSxzD8ixd/view?usp=sharing. El dataset son compras de productos que diferentes clientes realizaron durante un black sales. El dataset contiene información sobre las transacciones y el objetivo es poder utilizar el dataset para crear diferentes modelos que puedan predecir cuánto un cliente está dispuesto a gastar en un producto en el futuro. Particularmente, vamos a tratar este problema como una clasificación binaria donde queremos averiguar si el cliente va a gastar mucha plata (más de 9000) o poca plata (menos de 9000).\n",
    "\n",
    "- a)\tEntrenar un modelo de deep learning que no utilice embeddings.\n",
    "- b)\tEntrenar un modelo de deep learning que utilice embeddings tanto para los productos como los usuarios. Realizar el mapeo de identificador de producto y usuarios a indices antes de separar el dataset en training, validation y testing.\n",
    "- c)\tCompare el score de cada modelo y comente lo necesario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/fermonzongh/CEIA/main/Deep%20Learning/Examen/dataset_black_sales.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de datos y feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550068"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   User_ID                     550068 non-null  int64  \n",
      " 1   Product_ID                  550068 non-null  object \n",
      " 2   Gender                      550068 non-null  object \n",
      " 3   Age                         550068 non-null  object \n",
      " 4   Occupation                  550068 non-null  int64  \n",
      " 5   City_Category               550068 non-null  object \n",
      " 6   Stay_In_Current_City_Years  550068 non-null  object \n",
      " 7   Marital_Status              550068 non-null  int64  \n",
      " 8   Product_Category_1          550068 non-null  int64  \n",
      " 9   Product_Category_2          376430 non-null  float64\n",
      " 10  Product_Category_3          166821 non-null  float64\n",
      " 11  Purchase                    550068 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 50.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie=[]\n",
    "for product_id in df['Product_ID']:\n",
    "    if product_id[0]=='P':\n",
    "        product_id=product_id[1:]\n",
    "        serie.append(int(product_id))\n",
    "df['Product_ID']=serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'M'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genero=[]\n",
    "for gender in df['Gender']:\n",
    "    if gender=='F':\n",
    "        genero.append(0)\n",
    "    elif gender=='M':\n",
    "        genero.append(1)\n",
    "df['Gender']=genero\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0-17', '55+', '26-35', '46-50', '51-55', '36-45', '18-25'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>69042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>248942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>87842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>85442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>285442</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000003</td>\n",
       "      <td>193542</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000004</td>\n",
       "      <td>184942</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000004</td>\n",
       "      <td>346142</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000004</td>\n",
       "      <td>97242</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000005</td>\n",
       "      <td>274942</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Product_ID  Gender  Age  Occupation City_Category  \\\n",
       "0  1000001       69042       0    0          10             A   \n",
       "1  1000001      248942       0    0          10             A   \n",
       "2  1000001       87842       0    0          10             A   \n",
       "3  1000001       85442       0    0          10             A   \n",
       "4  1000002      285442       1    6          16             C   \n",
       "5  1000003      193542       1    2          15             A   \n",
       "6  1000004      184942       1    4           7             B   \n",
       "7  1000004      346142       1    4           7             B   \n",
       "8  1000004       97242       1    4           7             B   \n",
       "9  1000005      274942       1    2          20             A   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "5                          3               0                   1   \n",
       "6                          2               1                   1   \n",
       "7                          2               1                   1   \n",
       "8                          2               1                   1   \n",
       "9                          1               1                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  \n",
       "5                 2.0                 NaN     15227  \n",
       "6                 8.0                17.0     19215  \n",
       "7                15.0                 NaN     15854  \n",
       "8                16.0                 NaN     15686  \n",
       "9                 NaN                 NaN      7871  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup_nums = {\"Age\":     {\"0-17\": 0, \"18-25\": 1,\"26-35\": 2,\"36-45\": 3,\"46-50\": 4,\"51-55\":5,\"55+\":6}}\n",
    "df=df.replace(cleanup_nums)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '4+', '3', '1', '0'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Stay_In_Current_City_Years'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>69042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>248942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>87842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>85442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>285442</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000003</td>\n",
       "      <td>193542</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000004</td>\n",
       "      <td>184942</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000004</td>\n",
       "      <td>346142</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000004</td>\n",
       "      <td>97242</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000005</td>\n",
       "      <td>274942</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Product_ID  Gender  Age  Occupation City_Category  \\\n",
       "0  1000001       69042       0    0          10             A   \n",
       "1  1000001      248942       0    0          10             A   \n",
       "2  1000001       87842       0    0          10             A   \n",
       "3  1000001       85442       0    0          10             A   \n",
       "4  1000002      285442       1    6          16             C   \n",
       "5  1000003      193542       1    2          15             A   \n",
       "6  1000004      184942       1    4           7             B   \n",
       "7  1000004      346142       1    4           7             B   \n",
       "8  1000004       97242       1    4           7             B   \n",
       "9  1000005      274942       1    2          20             A   \n",
       "\n",
       "   Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                           2               0                   3   \n",
       "1                           2               0                   1   \n",
       "2                           2               0                  12   \n",
       "3                           2               0                  12   \n",
       "4                           4               0                   8   \n",
       "5                           3               0                   1   \n",
       "6                           2               1                   1   \n",
       "7                           2               1                   1   \n",
       "8                           2               1                   1   \n",
       "9                           1               1                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  \n",
       "5                 2.0                 NaN     15227  \n",
       "6                 8.0                17.0     19215  \n",
       "7                15.0                 NaN     15854  \n",
       "8                16.0                 NaN     15686  \n",
       "9                 NaN                 NaN      7871  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup_nums = {\"Stay_In_Current_City_Years\":     {\"0\": 0, \"1\": 1,\"2\": 2,\"3\": 3,\"4+\": 4,}}\n",
    "df=df.replace(cleanup_nums)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'C', 'B'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['City_Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>69042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>248942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>87842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>85442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>285442</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000003</td>\n",
       "      <td>193542</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000004</td>\n",
       "      <td>184942</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000004</td>\n",
       "      <td>346142</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000004</td>\n",
       "      <td>97242</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000005</td>\n",
       "      <td>274942</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Product_ID  Gender  Age  Occupation  City_Category  \\\n",
       "0  1000001       69042       0    0          10              0   \n",
       "1  1000001      248942       0    0          10              0   \n",
       "2  1000001       87842       0    0          10              0   \n",
       "3  1000001       85442       0    0          10              0   \n",
       "4  1000002      285442       1    6          16              2   \n",
       "5  1000003      193542       1    2          15              0   \n",
       "6  1000004      184942       1    4           7              1   \n",
       "7  1000004      346142       1    4           7              1   \n",
       "8  1000004       97242       1    4           7              1   \n",
       "9  1000005      274942       1    2          20              0   \n",
       "\n",
       "   Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                           2               0                   3   \n",
       "1                           2               0                   1   \n",
       "2                           2               0                  12   \n",
       "3                           2               0                  12   \n",
       "4                           4               0                   8   \n",
       "5                           3               0                   1   \n",
       "6                           2               1                   1   \n",
       "7                           2               1                   1   \n",
       "8                           2               1                   1   \n",
       "9                           1               1                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  \n",
       "5                 2.0                 NaN     15227  \n",
       "6                 8.0                17.0     19215  \n",
       "7                15.0                 NaN     15854  \n",
       "8                16.0                 NaN     15686  \n",
       "9                 NaN                 NaN      7871  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup_nums = {\"City_Category\":     {\"A\": 0, \"B\": 1,\"C\": 2}}\n",
    "df=df.replace(cleanup_nums)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 173638, 383247)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Product_Category_1\"].isnull().sum(),df[\"Product_Category_2\"].isnull().sum(),df[\"Product_Category_3\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>69042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>248942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>87842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>85442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>285442</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000003</td>\n",
       "      <td>193542</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000004</td>\n",
       "      <td>184942</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000004</td>\n",
       "      <td>346142</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000004</td>\n",
       "      <td>97242</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000005</td>\n",
       "      <td>274942</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Product_ID  Gender  Age  Occupation  City_Category  \\\n",
       "0  1000001       69042       0    0          10              0   \n",
       "1  1000001      248942       0    0          10              0   \n",
       "2  1000001       87842       0    0          10              0   \n",
       "3  1000001       85442       0    0          10              0   \n",
       "4  1000002      285442       1    6          16              2   \n",
       "5  1000003      193542       1    2          15              0   \n",
       "6  1000004      184942       1    4           7              1   \n",
       "7  1000004      346142       1    4           7              1   \n",
       "8  1000004       97242       1    4           7              1   \n",
       "9  1000005      274942       1    2          20              0   \n",
       "\n",
       "   Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                           2               0                   3   \n",
       "1                           2               0                   1   \n",
       "2                           2               0                  12   \n",
       "3                           2               0                  12   \n",
       "4                           4               0                   8   \n",
       "5                           3               0                   1   \n",
       "6                           2               1                   1   \n",
       "7                           2               1                   1   \n",
       "8                           2               1                   1   \n",
       "9                           1               1                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 0.0                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 0.0                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 0.0                 NaN      7969  \n",
       "5                 2.0                 NaN     15227  \n",
       "6                 8.0                17.0     19215  \n",
       "7                15.0                 NaN     15854  \n",
       "8                16.0                 NaN     15686  \n",
       "9                 0.0                 NaN      7871  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Product_Category_2'] = df['Product_Category_2'].fillna(0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>69042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>248942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>87842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>85442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>285442</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000003</td>\n",
       "      <td>193542</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000004</td>\n",
       "      <td>184942</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000004</td>\n",
       "      <td>346142</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000004</td>\n",
       "      <td>97242</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000005</td>\n",
       "      <td>274942</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Product_ID  Gender  Age  Occupation  City_Category  \\\n",
       "0  1000001       69042       0    0          10              0   \n",
       "1  1000001      248942       0    0          10              0   \n",
       "2  1000001       87842       0    0          10              0   \n",
       "3  1000001       85442       0    0          10              0   \n",
       "4  1000002      285442       1    6          16              2   \n",
       "5  1000003      193542       1    2          15              0   \n",
       "6  1000004      184942       1    4           7              1   \n",
       "7  1000004      346142       1    4           7              1   \n",
       "8  1000004       97242       1    4           7              1   \n",
       "9  1000005      274942       1    2          20              0   \n",
       "\n",
       "   Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                           2               0                   3   \n",
       "1                           2               0                   1   \n",
       "2                           2               0                  12   \n",
       "3                           2               0                  12   \n",
       "4                           4               0                   8   \n",
       "5                           3               0                   1   \n",
       "6                           2               1                   1   \n",
       "7                           2               1                   1   \n",
       "8                           2               1                   1   \n",
       "9                           1               1                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 0.0                 0.0      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 0.0                 0.0      1422  \n",
       "3                14.0                 0.0      1057  \n",
       "4                 0.0                 0.0      7969  \n",
       "5                 2.0                 0.0     15227  \n",
       "6                 8.0                17.0     19215  \n",
       "7                15.0                 0.0     15854  \n",
       "8                16.0                 0.0     15686  \n",
       "9                 0.0                 0.0      7871  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Product_Category_3'] = df['Product_Category_3'].fillna(0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   User_ID                     550068 non-null  int64  \n",
      " 1   Product_ID                  550068 non-null  int64  \n",
      " 2   Gender                      550068 non-null  int64  \n",
      " 3   Age                         550068 non-null  int64  \n",
      " 4   Occupation                  550068 non-null  int64  \n",
      " 5   City_Category               550068 non-null  int64  \n",
      " 6   Stay_In_Current_City_Years  550068 non-null  int64  \n",
      " 7   Marital_Status              550068 non-null  int64  \n",
      " 8   Product_Category_1          550068 non-null  int64  \n",
      " 9   Product_Category_2          550068 non-null  float64\n",
      " 10  Product_Category_3          550068 non-null  float64\n",
      " 11  Purchase                    550068 non-null  int64  \n",
      "dtypes: float64(2), int64(10)\n",
      "memory usage: 50.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases=[]\n",
    "for purchase in df['Purchase']:\n",
    "    if purchase<9000:\n",
    "        purchases.append(0)\n",
    "    elif purchase>=9000:\n",
    "        purchases.append(1)\n",
    "df['Purchase']=purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>69042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>248942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>87842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>85442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>285442</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000003</td>\n",
       "      <td>193542</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000004</td>\n",
       "      <td>184942</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000004</td>\n",
       "      <td>346142</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000004</td>\n",
       "      <td>97242</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000005</td>\n",
       "      <td>274942</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Product_ID  Gender  Age  Occupation  City_Category  \\\n",
       "0  1000001       69042       0    0          10              0   \n",
       "1  1000001      248942       0    0          10              0   \n",
       "2  1000001       87842       0    0          10              0   \n",
       "3  1000001       85442       0    0          10              0   \n",
       "4  1000002      285442       1    6          16              2   \n",
       "5  1000003      193542       1    2          15              0   \n",
       "6  1000004      184942       1    4           7              1   \n",
       "7  1000004      346142       1    4           7              1   \n",
       "8  1000004       97242       1    4           7              1   \n",
       "9  1000005      274942       1    2          20              0   \n",
       "\n",
       "   Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                           2               0                   3   \n",
       "1                           2               0                   1   \n",
       "2                           2               0                  12   \n",
       "3                           2               0                  12   \n",
       "4                           4               0                   8   \n",
       "5                           3               0                   1   \n",
       "6                           2               1                   1   \n",
       "7                           2               1                   1   \n",
       "8                           2               1                   1   \n",
       "9                           1               1                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 0.0                 0.0         0  \n",
       "1                 6.0                14.0         1  \n",
       "2                 0.0                 0.0         0  \n",
       "3                14.0                 0.0         0  \n",
       "4                 0.0                 0.0         0  \n",
       "5                 2.0                 0.0         1  \n",
       "6                 8.0                17.0         1  \n",
       "7                15.0                 0.0         1  \n",
       "8                16.0                 0.0         1  \n",
       "9                 0.0                 0.0         0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3631"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.Product_ID.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division de dataset en Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,0:-1],df.iloc[:,-1],train_size=0.8,random_state=42)\n",
    "x = df.drop(['Purchase','User_ID','Product_ID'], axis=1) \n",
    "user_id=df['User_ID']\n",
    "product_id=df['Product_ID']\n",
    "y = df['Purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([513236, 141308,  92892, ..., 458705, 469640,  29072])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.permutation(x.shape[0])\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440054,)\n",
      "(110014,)\n"
     ]
    }
   ],
   "source": [
    "train_idx = idx[0:int(0.80*len(idx))]\n",
    "valid_idx = idx[int(0.80*len(idx)):]\n",
    "print(train_idx.shape)\n",
    "print(valid_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x[train_idx]\n",
    "y_train = y[train_idx]\n",
    "X_test = x[valid_idx]\n",
    "y_test = y[valid_idx]\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "n_valid = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = StandardScaler()\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando/anaconda3/envs/pytorch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch necesita de una clase de dataset que extienda de torch.utils.data.Dataset\n",
    "# Esta clase dataset debe sobreescribir los métodos init, len y getitem\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "  #__init__ guarda el dataset en una variable de clase\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "  # __len__ define el comportamiento de la función len() sobre el objeto\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "  # __getitem__ define el comportamiento de los []\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MyDataset(X_train, y_train)\n",
    "valid_ds = MyDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch utiliza DataLoader para entregar los dataset de a batches\n",
    "train_dataloader = DataLoader(train_ds, batch_size = 128, shuffle= True)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "    # Defino la arquitectura de la red\n",
    "        super().__init__()\n",
    "        self.linear_1 = torch.nn.Linear(in_features=9, out_features=200, bias=True)\n",
    "        self.relu_1 = torch.nn.Tanh()\n",
    "        self.drop_1 = torch.nn.Dropout(p=0.2)\n",
    "        self.linear_2 = torch.nn.Linear(in_features = 200, out_features=100, bias=True)\n",
    "        self.relu_2 = torch.nn.Tanh()\n",
    "        self.drop_2 = torch.nn.Dropout(p=0.2)\n",
    "        self.linear_3 = torch.nn.Linear(in_features = 100, out_features=55, bias=True)\n",
    "        self.relu_3 = torch.nn.Tanh()\n",
    "        self.drop_3 = torch.nn.Dropout(p=0.2)\n",
    "        self.output = torch.nn.Linear(in_features = 55, out_features= 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "    # Defino el cálculo del paso forward\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.drop_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.drop_2(x)\n",
    "        x = self.linear_3(x)\n",
    "        x = self.relu_3(x)\n",
    "        x = self.drop_3(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos la red\n",
    "nnet = NNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.57374836, -1.10405325, -0.62369215,  1.25946145,  0.8847452 ,\n",
       "        -0.83291453, -1.11883373,  1.33095284, -0.61396699]),\n",
       " 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(nnet.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copio la red neuronal al dispositivo donde entrene la red neuronal\n",
    "nnet = nnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0 | Train/Valid loss: 0.403 / 0.380 | Train/Valid accuracy: 0.823 / 0.834\n",
      " Epoch 1 | Train/Valid loss: 0.396 / 0.377 | Train/Valid accuracy: 0.826 / 0.833\n",
      " Epoch 2 | Train/Valid loss: 0.393 / 0.368 | Train/Valid accuracy: 0.825 / 0.835\n",
      " Epoch 3 | Train/Valid loss: 0.389 / 0.366 | Train/Valid accuracy: 0.827 / 0.835\n",
      " Epoch 4 | Train/Valid loss: 0.387 / 0.365 | Train/Valid accuracy: 0.827 / 0.842\n",
      " Epoch 5 | Train/Valid loss: 0.385 / 0.376 | Train/Valid accuracy: 0.829 / 0.837\n",
      " Epoch 6 | Train/Valid loss: 0.384 / 0.364 | Train/Valid accuracy: 0.829 / 0.841\n",
      " Epoch 7 | Train/Valid loss: 0.383 / 0.368 | Train/Valid accuracy: 0.828 / 0.836\n",
      " Epoch 8 | Train/Valid loss: 0.381 / 0.376 | Train/Valid accuracy: 0.829 / 0.835\n",
      " Epoch 9 | Train/Valid loss: 0.376 / 0.352 | Train/Valid accuracy: 0.832 / 0.850\n",
      " Epoch 10 | Train/Valid loss: 0.376 / 0.350 | Train/Valid accuracy: 0.832 / 0.850\n",
      " Epoch 11 | Train/Valid loss: 0.375 / 0.350 | Train/Valid accuracy: 0.833 / 0.851\n",
      " Epoch 12 | Train/Valid loss: 0.374 / 0.354 | Train/Valid accuracy: 0.834 / 0.852\n",
      " Epoch 13 | Train/Valid loss: 0.373 / 0.356 | Train/Valid accuracy: 0.835 / 0.843\n",
      " Epoch 14 | Train/Valid loss: 0.373 / 0.351 | Train/Valid accuracy: 0.834 / 0.844\n",
      " Epoch 15 | Train/Valid loss: 0.372 / 0.350 | Train/Valid accuracy: 0.835 / 0.852\n",
      " Epoch 16 | Train/Valid loss: 0.372 / 0.346 | Train/Valid accuracy: 0.835 / 0.852\n",
      " Epoch 17 | Train/Valid loss: 0.371 / 0.348 | Train/Valid accuracy: 0.834 / 0.852\n",
      " Epoch 18 | Train/Valid loss: 0.372 / 0.344 | Train/Valid accuracy: 0.834 / 0.853\n",
      " Epoch 19 | Train/Valid loss: 0.373 / 0.347 | Train/Valid accuracy: 0.833 / 0.845\n",
      " Epoch 20 | Train/Valid loss: 0.373 / 0.355 | Train/Valid accuracy: 0.833 / 0.845\n",
      " Epoch 21 | Train/Valid loss: 0.371 / 0.349 | Train/Valid accuracy: 0.835 / 0.853\n",
      " Epoch 22 | Train/Valid loss: 0.371 / 0.347 | Train/Valid accuracy: 0.835 / 0.845\n",
      " Epoch 23 | Train/Valid loss: 0.372 / 0.346 | Train/Valid accuracy: 0.834 / 0.850\n",
      " Epoch 24 | Train/Valid loss: 0.370 / 0.344 | Train/Valid accuracy: 0.835 / 0.852\n",
      " Epoch 25 | Train/Valid loss: 0.373 / 0.353 | Train/Valid accuracy: 0.833 / 0.848\n",
      " Epoch 26 | Train/Valid loss: 0.373 / 0.346 | Train/Valid accuracy: 0.832 / 0.850\n",
      " Epoch 27 | Train/Valid loss: 0.371 / 0.346 | Train/Valid accuracy: 0.834 / 0.853\n",
      " Epoch 28 | Train/Valid loss: 0.371 / 0.345 | Train/Valid accuracy: 0.835 / 0.853\n",
      " Epoch 29 | Train/Valid loss: 0.370 / 0.342 | Train/Valid accuracy: 0.835 / 0.852\n",
      " Epoch 30 | Train/Valid loss: 0.370 / 0.345 | Train/Valid accuracy: 0.836 / 0.852\n",
      " Epoch 31 | Train/Valid loss: 0.370 / 0.345 | Train/Valid accuracy: 0.836 / 0.853\n",
      " Epoch 32 | Train/Valid loss: 0.370 / 0.348 | Train/Valid accuracy: 0.835 / 0.845\n",
      " Epoch 33 | Train/Valid loss: 0.369 / 0.348 | Train/Valid accuracy: 0.836 / 0.852\n",
      " Epoch 34 | Train/Valid loss: 0.370 / 0.361 | Train/Valid accuracy: 0.835 / 0.845\n",
      " Epoch 35 | Train/Valid loss: 0.370 / 0.343 | Train/Valid accuracy: 0.836 / 0.851\n",
      " Epoch 36 | Train/Valid loss: 0.371 / 0.342 | Train/Valid accuracy: 0.835 / 0.853\n",
      " Epoch 37 | Train/Valid loss: 0.369 / 0.347 | Train/Valid accuracy: 0.836 / 0.845\n",
      " Epoch 38 | Train/Valid loss: 0.370 / 0.347 | Train/Valid accuracy: 0.836 / 0.852\n",
      " Epoch 39 | Train/Valid loss: 0.370 / 0.345 | Train/Valid accuracy: 0.836 / 0.853\n",
      " Epoch 40 | Train/Valid loss: 0.371 / 0.347 | Train/Valid accuracy: 0.836 / 0.852\n",
      " Epoch 41 | Train/Valid loss: 0.370 / 0.344 | Train/Valid accuracy: 0.835 / 0.853\n",
      " Epoch 42 | Train/Valid loss: 0.371 / 0.350 | Train/Valid accuracy: 0.835 / 0.852\n",
      " Epoch 43 | Train/Valid loss: 0.370 / 0.345 | Train/Valid accuracy: 0.836 / 0.853\n",
      " Epoch 44 | Train/Valid loss: 0.369 / 0.342 | Train/Valid accuracy: 0.836 / 0.853\n",
      " Epoch 45 | Train/Valid loss: 0.369 / 0.341 | Train/Valid accuracy: 0.837 / 0.852\n",
      " Epoch 46 | Train/Valid loss: 0.369 / 0.349 | Train/Valid accuracy: 0.836 / 0.845\n",
      " Epoch 47 | Train/Valid loss: 0.369 / 0.350 | Train/Valid accuracy: 0.837 / 0.853\n",
      " Epoch 48 | Train/Valid loss: 0.369 / 0.342 | Train/Valid accuracy: 0.837 / 0.853\n",
      " Epoch 49 | Train/Valid loss: 0.368 / 0.342 | Train/Valid accuracy: 0.838 / 0.852\n",
      " Epoch 50 | Train/Valid loss: 0.369 / 0.343 | Train/Valid accuracy: 0.836 / 0.852\n",
      " Epoch 51 | Train/Valid loss: 0.370 / 0.350 | Train/Valid accuracy: 0.836 / 0.844\n",
      " Epoch 52 | Train/Valid loss: 0.371 / 0.345 | Train/Valid accuracy: 0.836 / 0.853\n",
      " Epoch 53 | Train/Valid loss: 0.370 / 0.353 | Train/Valid accuracy: 0.836 / 0.845\n",
      " Epoch 54 | Train/Valid loss: 0.370 / 0.343 | Train/Valid accuracy: 0.836 / 0.852\n",
      " Epoch 55 | Train/Valid loss: 0.369 / 0.343 | Train/Valid accuracy: 0.836 / 0.852\n",
      " Epoch 56 | Train/Valid loss: 0.369 / 0.350 | Train/Valid accuracy: 0.838 / 0.845\n",
      " Epoch 57 | Train/Valid loss: 0.368 / 0.343 | Train/Valid accuracy: 0.838 / 0.852\n",
      " Epoch 58 | Train/Valid loss: 0.370 / 0.343 | Train/Valid accuracy: 0.837 / 0.853\n",
      " Epoch 59 | Train/Valid loss: 0.370 / 0.344 | Train/Valid accuracy: 0.838 / 0.852\n",
      " Epoch 60 | Train/Valid loss: 0.370 / 0.344 | Train/Valid accuracy: 0.837 / 0.852\n",
      " Epoch 61 | Train/Valid loss: 0.372 / 0.345 | Train/Valid accuracy: 0.835 / 0.852\n",
      " Epoch 62 | Train/Valid loss: 0.370 / 0.342 | Train/Valid accuracy: 0.836 / 0.853\n",
      " Epoch 63 | Train/Valid loss: 0.369 / 0.341 | Train/Valid accuracy: 0.837 / 0.852\n",
      " Epoch 64 | Train/Valid loss: 0.368 / 0.350 | Train/Valid accuracy: 0.837 / 0.853\n",
      " Epoch 65 | Train/Valid loss: 0.369 / 0.341 | Train/Valid accuracy: 0.837 / 0.853\n",
      " Epoch 66 | Train/Valid loss: 0.368 / 0.346 | Train/Valid accuracy: 0.837 / 0.851\n",
      " Epoch 67 | Train/Valid loss: 0.368 / 0.344 | Train/Valid accuracy: 0.838 / 0.853\n",
      " Epoch 68 | Train/Valid loss: 0.367 / 0.342 | Train/Valid accuracy: 0.838 / 0.852\n",
      " Epoch 69 | Train/Valid loss: 0.367 / 0.359 | Train/Valid accuracy: 0.839 / 0.845\n",
      " Epoch 70 | Train/Valid loss: 0.370 / 0.346 | Train/Valid accuracy: 0.836 / 0.845\n",
      " Epoch 71 | Train/Valid loss: 0.369 / 0.350 | Train/Valid accuracy: 0.838 / 0.853\n",
      " Epoch 72 | Train/Valid loss: 0.368 / 0.347 | Train/Valid accuracy: 0.838 / 0.853\n",
      " Epoch 73 | Train/Valid loss: 0.367 / 0.346 | Train/Valid accuracy: 0.839 / 0.852\n",
      " Epoch 74 | Train/Valid loss: 0.367 / 0.342 | Train/Valid accuracy: 0.839 / 0.852\n",
      " Epoch 75 | Train/Valid loss: 0.367 / 0.347 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 76 | Train/Valid loss: 0.368 / 0.348 | Train/Valid accuracy: 0.838 / 0.853\n",
      " Epoch 77 | Train/Valid loss: 0.367 / 0.344 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 78 | Train/Valid loss: 0.368 / 0.350 | Train/Valid accuracy: 0.839 / 0.850\n",
      " Epoch 79 | Train/Valid loss: 0.367 / 0.349 | Train/Valid accuracy: 0.840 / 0.853\n",
      " Epoch 80 | Train/Valid loss: 0.367 / 0.343 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 81 | Train/Valid loss: 0.367 / 0.354 | Train/Valid accuracy: 0.839 / 0.845\n",
      " Epoch 82 | Train/Valid loss: 0.368 / 0.344 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 83 | Train/Valid loss: 0.367 / 0.341 | Train/Valid accuracy: 0.840 / 0.853\n",
      " Epoch 84 | Train/Valid loss: 0.367 / 0.342 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 85 | Train/Valid loss: 0.367 / 0.341 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 86 | Train/Valid loss: 0.366 / 0.344 | Train/Valid accuracy: 0.839 / 0.845\n",
      " Epoch 87 | Train/Valid loss: 0.366 / 0.359 | Train/Valid accuracy: 0.840 / 0.845\n",
      " Epoch 88 | Train/Valid loss: 0.367 / 0.340 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 89 | Train/Valid loss: 0.368 / 0.346 | Train/Valid accuracy: 0.839 / 0.845\n",
      " Epoch 90 | Train/Valid loss: 0.366 / 0.341 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 91 | Train/Valid loss: 0.367 / 0.342 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 92 | Train/Valid loss: 0.368 / 0.353 | Train/Valid accuracy: 0.838 / 0.845\n",
      " Epoch 93 | Train/Valid loss: 0.367 / 0.341 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 94 | Train/Valid loss: 0.368 / 0.340 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 95 | Train/Valid loss: 0.366 / 0.346 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 96 | Train/Valid loss: 0.367 / 0.351 | Train/Valid accuracy: 0.839 / 0.845\n",
      " Epoch 97 | Train/Valid loss: 0.367 / 0.341 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 98 | Train/Valid loss: 0.366 / 0.341 | Train/Valid accuracy: 0.839 / 0.853\n",
      " Epoch 99 | Train/Valid loss: 0.367 / 0.341 | Train/Valid accuracy: 0.839 / 0.852\n"
     ]
    }
   ],
   "source": [
    "# cantidad de epochs\n",
    "epochs = 100\n",
    "\n",
    "train_loss_by_epoch=[]\n",
    "valid_loss_by_epoch=[]\n",
    "early_stop=0\n",
    "valid_accuracy=0\n",
    "\n",
    "# Doble loop algoritmo Mini-Batch\n",
    "for epoch in range(epochs):\n",
    "  \n",
    "    ############################################\n",
    "    ## Entrenamiento\n",
    "    ############################################\n",
    "    nnet.train(True)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_y_hat = []\n",
    "    epoch_y = []\n",
    "  \n",
    "    for i,data in enumerate(train_dataloader):\n",
    "      # Obtengo los datos del batch de entrenamiento\n",
    "        x_batch, y_batch = data\n",
    "        # Copio el batch al dispositivo donde entreno la red neuronal\n",
    "        x_batch = x_batch.to(device).float()\n",
    "        y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
    "\n",
    "        # Paso forward\n",
    "        # Limpio optimizer para empezar un nuevo cálculo de gradiente\n",
    "        optimizer.zero_grad()\n",
    "        nnet_output = nnet(x_batch)\n",
    "        y_batch_hat = torch.sigmoid(nnet_output)\n",
    "        \n",
    "        # Calculo el loss\n",
    "        loss = loss_function(nnet_output, y_batch)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Actualizar los parámetros\n",
    "        optimizer.step()\n",
    "\n",
    "        # Almaceno los valores reales y mis predicciones para cálcular las métricas\n",
    "        epoch_y += list(y_batch.detach().cpu().numpy())\n",
    "        epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
    "        # Acumulo la loss del batch\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "\n",
    "  # Calculo la media de la loss\n",
    "    epoch_loss = epoch_loss / n_train\n",
    "  # Almaceno la loss de la epoch para graficar\n",
    "    train_loss_by_epoch.append(epoch_loss)\n",
    "  # Cálculo la métrica de la epoch\n",
    "    accuracy = accuracy_score(epoch_y, [j>=0.5 for j in epoch_y_hat])\n",
    "\n",
    "    ############################################\n",
    "    ## Validación\n",
    "    ############################################\n",
    "    # Desactivo el cálculo de gradiente para validación\n",
    "    nnet.train(False)\n",
    "\n",
    "    valid_epoch_loss = 0\n",
    "    valid_epoch_y_hat = []\n",
    "    valid_epoch_y = []\n",
    "\n",
    "    for i,data in enumerate(valid_dataloader):\n",
    "        # Obtengo los datos del batch de validación\n",
    "        x_batch, y_batch = data\n",
    "        # Copio el batch al dispositivo donde entreno la red neuronal\n",
    "        x_batch = x_batch.to(device).float()\n",
    "        y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
    "\n",
    "        # Paso forward\n",
    "        nnet_output = nnet(x_batch)\n",
    "        y_batch_hat = torch.sigmoid(nnet_output)\n",
    "    \n",
    "        # Calculo el loss\n",
    "        loss = loss_function(nnet_output, y_batch)\n",
    "\n",
    "        # En validación no hago backpropagation!!\n",
    "\n",
    "        # Almaceno los valores reales y mis predicciones para cálcular las métricas\n",
    "        valid_epoch_y += list(y_batch.detach().cpu().numpy())\n",
    "        valid_epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
    "        # Acumulo la loss del batch\n",
    "        valid_epoch_loss = valid_epoch_loss + loss.item()\n",
    "\n",
    "    # Calculo la media de la loss\n",
    "    valid_epoch_loss = valid_epoch_loss / n_valid\n",
    "    # Almaceno la loss de la epoch para graficar\n",
    "    valid_loss_by_epoch.append(valid_epoch_loss)\n",
    "    # Cálculo la métrica de la epoch\n",
    "    prev_acc = valid_accuracy\n",
    "    valid_accuracy = accuracy_score(valid_epoch_y, [j>=0.5 for j in valid_epoch_y_hat])\n",
    "    if abs(valid_accuracy-prev_acc)<0.0005:\n",
    "        early_stop+=1\n",
    "        if early_stop==5:\n",
    "            break\n",
    "    else:\n",
    "        early_stop=0\n",
    "\n",
    "    ############################################\n",
    "    ## Impresión de resultados por epoch\n",
    "    ############################################\n",
    "    print(f\" Epoch {epoch} | \" \\\n",
    "        f\"Train/Valid loss: {epoch_loss:.3f} / {valid_epoch_loss:.3f} | \" \\\n",
    "        f\"Train/Valid accuracy: {accuracy:.3f} / {valid_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'BCE')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1= plt.subplots(1,1)\n",
    "ax1.plot(train_loss_by_epoch, label=\"Train loss\")\n",
    "ax1.plot(valid_loss_by_epoch, label=\"Validation loss\")\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Loss by epoch\")\n",
    "ax1.set_xlabel(\"epoch\")\n",
    "ax1.set_ylabel(\"BCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo con Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5891, 3631)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_id.unique()),len(product_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_to_idx = {value:i for i,value in enumerate(user_id.unique())}\n",
    "product_id_to_idx = {value:i for i,value in enumerate(product_id.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector de vendor_idx en el dataset\n",
    "user_idx = np.array([user_id_to_idx[value] for value in user_id])\n",
    "product_idx = np.array([product_id_to_idx[value] for value in product_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido el vector vendor_idx en entrenamiento y validación\n",
    "user_idx_train = user_idx[train_idx]\n",
    "user_idx_valid = user_idx[valid_idx]\n",
    "product_idx_train = product_idx[train_idx]\n",
    "product_idx_valid = product_idx[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase Dataset de Pytorch con embeddings\n",
    "class MyDatasetWithEmbddings(Dataset):\n",
    "\n",
    "    def __init__(self, x, user_idx, product_idx, y):\n",
    "        self.x = x\n",
    "        self.user_idx = user_idx\n",
    "        self.product_idx = product_idx\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.user_idx[idx],self.product_idx[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_embeddings = MyDatasetWithEmbddings(X_train, user_idx_train, product_idx_train, y_train)\n",
    "valid_ds_embeddings = MyDatasetWithEmbddings(X_test, user_idx_valid, product_idx_valid, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_emb = DataLoader(train_ds_embeddings, batch_size =64, shuffle= True)\n",
    "valid_dataloader_emb = DataLoader(valid_ds_embeddings, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitectura con embeddings\n",
    "class NNetWithEmbeddings(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings_user = torch.nn.Embedding(num_embeddings=5891, embedding_dim=15)\n",
    "        self.embeddings_product = torch.nn.Embedding(num_embeddings=3631, embedding_dim=10)\n",
    "        self.linear_1 = torch.nn.Linear(in_features=9+15+10, out_features=200, bias=True)\n",
    "        self.relu_1 = torch.nn.Tanh()\n",
    "        self.drop_1 = torch.nn.Dropout(p=0.2)\n",
    "        self.linear_2 = torch.nn.Linear(in_features = 200, out_features=100, bias=True)\n",
    "        self.relu_2 = torch.nn.Tanh()\n",
    "        self.drop_2 = torch.nn.Dropout(p=0.2)\n",
    "        self.linear_3 = torch.nn.Linear(in_features = 100, out_features=55, bias=True)\n",
    "        self.relu_3 = torch.nn.Tanh()\n",
    "        self.drop_3 = torch.nn.Dropout(p=0.2)\n",
    "        self.output = torch.nn.Linear(in_features = 55, out_features= 1, bias=True)\n",
    "\n",
    "    def forward(self, x, user_idx,product_idx):\n",
    "        embeddings_outputs_user = self.embeddings_user(user_idx)\n",
    "        embeddings_outputs_product = self.embeddings_product(product_idx)\n",
    "        x = torch.cat([x, embeddings_outputs_user, embeddings_outputs_product], dim=1)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.drop_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.drop_2(x)\n",
    "        x = self.linear_3(x)\n",
    "        x = self.relu_3(x)\n",
    "        x = self.drop_3(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnnetWithEmbeddings = NNetWithEmbeddings()\n",
    "nnnetWithEmbeddings = nnnetWithEmbeddings.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "# Optimizador con regularización L2 (parámetro weight_decay)\n",
    "optimizer = torch.optim.Adam(nnnetWithEmbeddings.parameters(), lr=0.001, weight_decay=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0 | Train/Valid loss: 0.347 / 0.277 | Train/Valid accuracy: 0.847 / 0.880\n",
      " Epoch 1 | Train/Valid loss: 0.287 / 0.272 | Train/Valid accuracy: 0.874 / 0.880\n",
      " Epoch 2 | Train/Valid loss: 0.281 / 0.270 | Train/Valid accuracy: 0.876 / 0.880\n",
      " Epoch 3 | Train/Valid loss: 0.279 / 0.269 | Train/Valid accuracy: 0.877 / 0.880\n",
      " Epoch 4 | Train/Valid loss: 0.277 / 0.267 | Train/Valid accuracy: 0.878 / 0.881\n",
      " Epoch 5 | Train/Valid loss: 0.275 / 0.269 | Train/Valid accuracy: 0.879 / 0.880\n",
      " Epoch 6 | Train/Valid loss: 0.274 / 0.270 | Train/Valid accuracy: 0.879 / 0.879\n",
      " Epoch 7 | Train/Valid loss: 0.273 / 0.267 | Train/Valid accuracy: 0.879 / 0.882\n",
      " Epoch 8 | Train/Valid loss: 0.273 / 0.270 | Train/Valid accuracy: 0.880 / 0.883\n",
      " Epoch 9 | Train/Valid loss: 0.272 / 0.264 | Train/Valid accuracy: 0.880 / 0.883\n",
      " Epoch 10 | Train/Valid loss: 0.271 / 0.271 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 11 | Train/Valid loss: 0.271 / 0.265 | Train/Valid accuracy: 0.880 / 0.882\n",
      " Epoch 12 | Train/Valid loss: 0.271 / 0.265 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 13 | Train/Valid loss: 0.271 / 0.266 | Train/Valid accuracy: 0.880 / 0.882\n",
      " Epoch 14 | Train/Valid loss: 0.270 / 0.264 | Train/Valid accuracy: 0.880 / 0.883\n",
      " Epoch 15 | Train/Valid loss: 0.270 / 0.265 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 16 | Train/Valid loss: 0.270 / 0.264 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 17 | Train/Valid loss: 0.270 / 0.263 | Train/Valid accuracy: 0.880 / 0.883\n",
      " Epoch 18 | Train/Valid loss: 0.269 / 0.264 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 19 | Train/Valid loss: 0.268 / 0.264 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 20 | Train/Valid loss: 0.267 / 0.265 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 21 | Train/Valid loss: 0.267 / 0.263 | Train/Valid accuracy: 0.880 / 0.882\n",
      " Epoch 22 | Train/Valid loss: 0.266 / 0.262 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 23 | Train/Valid loss: 0.265 / 0.261 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 24 | Train/Valid loss: 0.265 / 0.262 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 25 | Train/Valid loss: 0.265 / 0.262 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 26 | Train/Valid loss: 0.265 / 0.264 | Train/Valid accuracy: 0.880 / 0.881\n",
      " Epoch 27 | Train/Valid loss: 0.265 / 0.265 | Train/Valid accuracy: 0.881 / 0.879\n",
      " Epoch 28 | Train/Valid loss: 0.265 / 0.263 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 29 | Train/Valid loss: 0.265 / 0.266 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 30 | Train/Valid loss: 0.265 / 0.263 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 31 | Train/Valid loss: 0.265 / 0.264 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 32 | Train/Valid loss: 0.265 / 0.261 | Train/Valid accuracy: 0.881 / 0.884\n",
      " Epoch 33 | Train/Valid loss: 0.265 / 0.263 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 34 | Train/Valid loss: 0.265 / 0.263 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 35 | Train/Valid loss: 0.265 / 0.262 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 36 | Train/Valid loss: 0.265 / 0.264 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 37 | Train/Valid loss: 0.265 / 0.264 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 38 | Train/Valid loss: 0.265 / 0.264 | Train/Valid accuracy: 0.881 / 0.881\n",
      " Epoch 39 | Train/Valid loss: 0.265 / 0.264 | Train/Valid accuracy: 0.881 / 0.883\n",
      " Epoch 40 | Train/Valid loss: 0.265 / 0.264 | Train/Valid accuracy: 0.881 / 0.881\n",
      " Epoch 41 | Train/Valid loss: 0.265 / 0.262 | Train/Valid accuracy: 0.880 / 0.882\n",
      " Epoch 42 | Train/Valid loss: 0.265 / 0.262 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 43 | Train/Valid loss: 0.265 / 0.263 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 44 | Train/Valid loss: 0.265 / 0.263 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 45 | Train/Valid loss: 0.265 / 0.264 | Train/Valid accuracy: 0.880 / 0.881\n",
      " Epoch 46 | Train/Valid loss: 0.265 / 0.266 | Train/Valid accuracy: 0.881 / 0.879\n",
      " Epoch 47 | Train/Valid loss: 0.265 / 0.268 | Train/Valid accuracy: 0.881 / 0.879\n",
      " Epoch 48 | Train/Valid loss: 0.265 / 0.264 | Train/Valid accuracy: 0.881 / 0.882\n",
      " Epoch 49 | Train/Valid loss: 0.265 / 0.263 | Train/Valid accuracy: 0.881 / 0.882\n"
     ]
    }
   ],
   "source": [
    "# cantidad de epochs\n",
    "epochs = 50\n",
    "\n",
    "train_loss_by_epoch=[]\n",
    "valid_loss_by_epoch=[]\n",
    "early_stop=0\n",
    "valid_accuracy=0\n",
    "\n",
    "# Doble loop algoritmo Mini-Batch\n",
    "for epoch in range(epochs):\n",
    "  \n",
    "  ############################################\n",
    "  ## Entrenamiento\n",
    "  ############################################\n",
    "    nnnetWithEmbeddings.train(True)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_y_hat = []\n",
    "    epoch_y = []\n",
    "  \n",
    "    for i,data in enumerate(train_dataloader_emb):\n",
    "        # Obtengo los datos del batch de entrenamiento\n",
    "        x_batch, embed_batch, product_batch, y_batch = data\n",
    "        # Copio el batch al dispositivo donde entreno la red neuronal\n",
    "        x_batch = x_batch.to(device).float()\n",
    "        embed_batch = embed_batch.to(device).int()\n",
    "        product_batch = product_batch.to(device).int()\n",
    "        y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
    "\n",
    "        # Paso forward\n",
    "        # Limpio optimizer para empezar un nuevo cálculo de gradiente\n",
    "        optimizer.zero_grad()\n",
    "        nnet_output = nnnetWithEmbeddings(x_batch, embed_batch,product_batch)\n",
    "        y_batch_hat = torch.sigmoid(nnet_output)\n",
    "    \n",
    "        # Calculo el loss\n",
    "        loss = loss_function(nnet_output, y_batch)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Actualizar los parámetros\n",
    "        optimizer.step()\n",
    "\n",
    "        # Almaceno los valores reales y mis predicciones para cálcular las métricas\n",
    "        epoch_y += list(y_batch.detach().cpu().numpy())\n",
    "        epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
    "        # Acumulo la loss del batch\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "\n",
    "  # Calculo la media de la loss\n",
    "    epoch_loss = epoch_loss / n_train\n",
    "  # Almaceno la loss de la epoch para graficar\n",
    "    train_loss_by_epoch.append(epoch_loss)\n",
    "  # Cálculo la métrica de la epoch\n",
    "    accuracy = accuracy_score(epoch_y, [j>=0.5 for j in epoch_y_hat])\n",
    "\n",
    "  ############################################\n",
    "  ## Validación\n",
    "  ############################################\n",
    "  # Desactivo el cálculo de gradiente para validación\n",
    "    nnnetWithEmbeddings.train(False)\n",
    "\n",
    "    valid_epoch_loss = 0\n",
    "    valid_epoch_y_hat = []\n",
    "    valid_epoch_y = []\n",
    "\n",
    "    for i,data in enumerate(valid_dataloader_emb):\n",
    "        # Obtengo los datos del batch de validación\n",
    "        x_batch, embed_batch,product_batch, y_batch = data\n",
    "        # Copio el batch al dispositivo donde entreno la red neuronal\n",
    "        x_batch = x_batch.to(device).float()\n",
    "        embed_batch = embed_batch.to(device).int()\n",
    "        product_batch = product_batch.to(device).int()\n",
    "        y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
    "\n",
    "        # Paso forward\n",
    "        nnet_output = nnnetWithEmbeddings(x_batch, embed_batch,product_batch)\n",
    "        y_batch_hat = torch.sigmoid(nnet_output)\n",
    "    \n",
    "        # Calculo el loss\n",
    "        loss = loss_function(nnet_output, y_batch)\n",
    "\n",
    "        # En validación no hago backpropagation\n",
    "\n",
    "        # Almaceno los valores reales y mis predicciones para cálcular las métricas\n",
    "        valid_epoch_y += list(y_batch.detach().cpu().numpy())\n",
    "        valid_epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
    "        # Acumulo la loss del batch\n",
    "        valid_epoch_loss = valid_epoch_loss + loss.item()\n",
    "\n",
    "      # Calculo la media de la loss\n",
    "    valid_epoch_loss = valid_epoch_loss / n_valid\n",
    "    # Almaceno la loss de la epoch para graficar\n",
    "    valid_loss_by_epoch.append(valid_epoch_loss)\n",
    "    # Cálculo la métrica de la epoch\n",
    "    prev_acc = valid_accuracy\n",
    "    valid_accuracy = accuracy_score(valid_epoch_y, [j>=0.5 for j in valid_epoch_y_hat])\n",
    "    if abs(valid_accuracy-prev_acc)<=0.0005:\n",
    "        early_stop+=1\n",
    "        if early_stop==5:\n",
    "            break\n",
    "    else:\n",
    "        early_stop=0\n",
    "    \n",
    "\n",
    "  ############################################\n",
    "  ## Impresión de resultados por epoch\n",
    "  ############################################\n",
    "    print(f\" Epoch {epoch} | \" \\\n",
    "        f\"Train/Valid loss: {epoch_loss:.3f} / {valid_epoch_loss:.3f} | \" \\\n",
    "        f\"Train/Valid accuracy: {accuracy:.3f} / {valid_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'BCE')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1= plt.subplots(1,1)\n",
    "ax1.plot(train_loss_by_epoch, label=\"Train loss\")\n",
    "ax1.plot(valid_loss_by_epoch, label=\"Validation loss\")\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Loss by epoch\")\n",
    "ax1.set_xlabel(\"epoch\")\n",
    "ax1.set_ylabel(\"BCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El entrenamiento con embeddings dio mejores resultados en accuracy y en loss, siendo esta mas baja. Pero esto es a costo de mayor tiempo de entrenamiento, fue mucho mas lo que demoró con embeddings que sin embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
